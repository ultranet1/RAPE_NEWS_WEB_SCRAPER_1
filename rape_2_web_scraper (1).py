# -*- coding: utf-8 -*-
"""RAPE_2_WEB_SCRAPER.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TDH3DvVM6pUublC9e3qPqj9uenMK0dXL
"""

! pip install selenium

!apt install chromium-chromedriver

import pandas as pd
import numpy as np
import selenium
import regex as rg 
import nltk
import sys

from selenium import webdriver
import time
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support.ui import Select
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.common.exceptions import TimeoutException

options = webdriver.ChromeOptions()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
 
options.add_argument("start-maximized")
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option('useAutomationExtension', False)
 
 
sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')
wd = webdriver.Chrome('chromedriver', options=options)

link_sheet= pd.read_excel('/content/drive/MyDrive/Colab Notebooks/selenium/new.xlsx',  )
link_sheet

"""# FOR LINDA_IKEJI"""

for i in link_sheet['linda_ikeji']:
  print(i)

story=[]
for i in link_sheet['linda_ikeji']:
  try:
    wd.get(str(i))
    time.sleep(2)
    p=wd.find_elements_by_class_name('description')
  
    for t in p:
      print(t.text)
      story.append(t.text)
  except:
    pass

len(story)

"""# For nairaland"""

naira= link_sheet['nairaland'].dropna()
for i in naira:
    print (i)

story1 =[]
for i in naira:
  try:
    wd.get(str(i))
    time.sleep(2)
    p=wd.find_elements_by_class_name('narrow')
  
    for t in p:
      print(t.text)
      story1.append(t.text)
  except:
    pass

story1a=story1[0:1]
story1a

story1b=story1[8:9]
story1b

"""# FOR PINK_REPUBLIC"""

link_sheet['pink_republic']
pink= link_sheet['pink_republic'].dropna()
for i in pink:
  print(i)

story2 =[]
for i in pink:
  try:
    wd.get(str(i))
    time.sleep(2)
    p=wd.find_elements_by_class_name('text_exposed_show')
  
    for t in p:
      print(t.text)
      story2.append(t.text)
  except:
    pass

story2=story2[0:1]

len(story2)

"""# For THE NEWS"""

the=link_sheet.the_news.dropna()
the
for i in the:
  print(i)

story3=[]
for i in the:
  try:
    wd.get(str(i))
    p=wd.find_elements_by_class_name('padding')
  
    for t in p:
      print(t.text)
      story3.append(t.text)
  except:
    pass

story3=story3[1:2]

"""# FOR SAHARA REPORTERS"""

s=link_sheet.sharara_reporters.dropna()
s
for i in s:
  print(i)

story4=[]
for i in s:
  try:
    wd.get(str(i))
    p=wd.find_elements_by_class_name('story-content')
  
    for t in p:
      print(t.text)
      story4.append(t.text)
  except:
    pass

"""# For flor_media"""

f=link_sheet.flor_media.dropna()
f
for i in f:
  print(i)

story5=[]
for i in f:
  try:
    wd.get(str(i))
    p=wd.find_elements_by_xpath('/html/body/div[1]/div[2]/div[4]/div/div/div/div[1]/div[4]/p')
  
    for t in p:
      print(t.text)
      story5.append(t.text)
  except:
    pass

len(story5)

"""# FOR DAILY POST"""

d=link_sheet['daily_post'].dropna()
d
for i in d:
  print(i)

story6=[]
for i in d:
  try:
    wd.get(str(i))
    p=wd.find_elements_by_id ('mvp-content-main')
  
    for t in p:
      print(t.text)
      story6.append(t.text)
  except:
    pass

"""# FOR PUNCH NG"""

p=link_sheet['punch_ng'].dropna()
p
for i in p:
  print(i)

story7=[]
for i in p:
  try:
    wd.get(str(i))
    p1=wd.find_elements_by_xpath ('/html/body/div[2]/div[2]/div/main/article/div[2]/div[4]/div')
  
    for t in p1:
      print(t.text)
      story7.append(t.text)
  except:
    pass

"""# FOR VANGUARD NEWS"""

v=link_sheet['vanguard'].dropna()
v
for i in v:
  print(i)

story8=[]
for i in v:
  try:
    wd.get(str(i))
    p1=wd.find_elements_by_id ('post-1437901')
  
    for t in p1:
      print(t.text)
      story8.append(t.text)
  except:
    pass

"""#FOR MSN"""

m=link_sheet['msn'].dropna()
m
for i in m:
  print(i)

story9=[]
for i in m:
  try:
    wd.get(str(i))
    p1=wd.find_elements_by_class_name ('articlebody')
  
    for t in p1:
      print(t.text)
      story9.append(t.text)
  except:
    pass

"""# FOR UR_REPORTS"""

u=link_sheet['ur_reports'].dropna()
u
for i in u:
  print(i)

story10=[]
for i in u:
  try:
    wd.get(str(i))
    p1=wd.find_elements_by_class_name ('td-ss-main-content')
  
    for t in p1:
      print(t.text)
      story10.append(t.text)
  except:
    pass

"""# for igbeere_news"""

t=link_sheet['the_nation'].dropna()
t
for i in t:
  print(i)

story11=[]
for i in t:
  try:
    wd.get(str(i))
    p1=wd.find_elements_by_class_name ('content-inner')
  
    for t in p1:
      print(t.text)
      story11.append(t.text)
  except:
    pass

"""# FOR news_daily_NG"""

nd=link_sheet['news_daily'].dropna()
nd
for i in nd:
  print(i)

story12=[]
for i in nd:
  try:
    wd.get(str(i))
    p1=wd.find_elements_by_class_name ('mh-content')
  
    for t in p1:
      print(t.text)
      story12.append(t.text)
  except:
    pass

"""#FOR headtropics"""

ms=link_sheet['msn.1'].dropna()
ms
for i in ms:
  print(i)

story13=[]
for i in ms:
  try:
    wd.get(str(i))
    p1=wd.find_elements_by_class_name ('articlebody')
  
    for t in p1:
      print(t.text)
      story13.append(t.text)
  except:
    pass

"""MERGE ALL STORY"""

data=pd.DataFrame(story)
data1=pd.DataFrame(story1a)
data1b=pd.DataFrame(story1b)
data2=pd.DataFrame(story2)
data3=pd.DataFrame(story3)
data4=pd.DataFrame(story4)
data5=pd.DataFrame(story5)
data6=pd.DataFrame(story6)
data7=pd.DataFrame(story7)
data8=pd.DataFrame(story8)
data9=pd.DataFrame(story9)
data10=pd.DataFrame(story10)
data11=pd.DataFrame(story11)
data12=pd.DataFrame(story12)
data13=pd.DataFrame(story13)

data_f=pd.concat([data,data1,data1b, data2, data3, data4, data5, data6, data7, data8, data9, data10, data11, data12, data13],)
data_f.reset_index(inplace = True)
data_f

data=data_f.drop(columns=['index'])
data['STORY'] = data
data=data.drop(columns=[0])
data

"""# BROKEN LINKS"""

link_sheet.columns

"""# 5 links are broken, The_nation, The pulse, independent, wuzup & msn.1"""

save=data.to_excel('/content/drive/MyDrive/Colab Notebooks/selenium/rape2.xlsx')